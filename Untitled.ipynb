{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b66022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young girl standing in a field with a flower in her hair\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#working model with audio\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained('vit-gpt2-image-captioning')\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\n",
    "    'vit-gpt2-image-captioning')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vit-gpt2-image-captioning')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n",
    "\n",
    "def predict_step(image):\n",
    "    pixel_values = feature_extractor(\n",
    "        images=[image], return_tensors='pt').pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    return preds[0]\n",
    "\n",
    "image = Image.open(r\"C:\\Users\\saisu\\OneDrive\\Desktop\\IMAGE CAPTIONING\\girl.jpg\")\n",
    "predcap=predict_step(image=image)\n",
    "print(predcap)\n",
    "try:\n",
    "    tts = gTTS(text=predcap, lang='en')\n",
    "    tts.save('temp.mp3')\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load('temp.mp3')            \n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pass\n",
    "\n",
    "                        \n",
    "    pygame.mixer.quit()\n",
    "    os.remove('temp.mp3')\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31c6c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young girl standing in a field with a flower in her hair\n",
      "a young girl standing in a field with a flower in her hair\n",
      "a young girl standing in a field with a flower in her hair\n",
      "a young girl standing in a field with a flower in her hair\n",
      "a young girl standing in a field with a flower in her hair\n"
     ]
    }
   ],
   "source": [
    "#trial 2 with trigger key\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import keyboard  # Add this import\n",
    "import os\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained('vit-gpt2-image-captioning')\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('vit-gpt2-image-captioning')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vit-gpt2-image-captioning')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n",
    "\n",
    "def predict_step(image):\n",
    "    pixel_values = feature_extractor(\n",
    "        images=[image], return_tensors='pt').pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    return preds[0]\n",
    "\n",
    "def caption_and_play(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    predcap = predict_step(image=image)\n",
    "    print(predcap)\n",
    "    \n",
    "    try:\n",
    "        tts = gTTS(text=predcap, lang='en')\n",
    "        tts.save('temp.mp3')\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load('temp.mp3')\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pass\n",
    "        pygame.mixer.quit()\n",
    "        os.remove('temp.mp3')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Define the callback function for the key press event\n",
    "def on_key_press(e):\n",
    "    if e.event_type == keyboard.KEY_DOWN:\n",
    "        # Call your image captioning function here\n",
    "        caption_and_play(r\"C:\\Users\\saisu\\OneDrive\\Desktop\\IMAGE CAPTIONING\\girl.jpg\")\n",
    "\n",
    "# Register the callback function for the specific key\n",
    "keyboard.on_press_key('p', on_key_press)\n",
    "\n",
    "# Keep the program running\n",
    "keyboard.wait('esc')  # You can change 'esc' to any other key if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Photo saved as input_img.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man in a dark room looking at the camera\n",
      "Photo saved as input_img.jpg\n",
      "a man holding a cell phone in his right hand\n",
      "Photo saved as input_img.jpg\n",
      "a man in a black shirt and glasses looking at something\n",
      "Photo saved as input_img.jpg\n",
      "a man holding a cell phone in his hand\n",
      "Photo saved as input_img.jpg\n",
      "a man holding a bottle of water in his hand\n"
     ]
    }
   ],
   "source": [
    "#prev work with camera feed\n",
    "#trial 2 with trigger key\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import keyboard  # Add this import\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained('vit-gpt2-image-captioning')\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('vit-gpt2-image-captioning')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vit-gpt2-image-captioning')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n",
    "\n",
    "def predict_step(image):\n",
    "    pixel_values = feature_extractor(\n",
    "        images=[image], return_tensors='pt').pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    return preds[0]\n",
    "\n",
    "def caption_and_play(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    predcap = predict_step(image=image)\n",
    "    print(predcap)\n",
    "    \n",
    "    try:\n",
    "        tts = gTTS(text=predcap, lang='en')\n",
    "        tts.save('temp.mp3')\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load('temp.mp3')\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pass\n",
    "        pygame.mixer.quit()\n",
    "        os.remove('temp.mp3')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Define the callback function for the key press event\n",
    "def on_key_press(e):\n",
    "    if e.event_type == keyboard.KEY_DOWN:\n",
    "        # Call your image captioning function here\n",
    "        #take image\n",
    "        cap = cv2.VideoCapture(0)  # 0 represents the default camera (usually the built-in webcam)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            photo_filename = f\"input_img.jpg\"\n",
    "            cv2.imwrite(photo_filename, frame)\n",
    "            print(f\"Photo saved as {photo_filename}\")\n",
    "        caption_and_play(r\"C:\\Users\\saisu\\OneDrive\\Desktop\\img captioning part 2\\input_img.jpg\")\n",
    "\n",
    "# Register the callback function for the specific key\n",
    "keyboard.on_press_key('p', on_key_press)\n",
    "\n",
    "# Keep the program running\n",
    "keyboard.wait('esc')  # You can change 'esc' to any other key if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5247669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
